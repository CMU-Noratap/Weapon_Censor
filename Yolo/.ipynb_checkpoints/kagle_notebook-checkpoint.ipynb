{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#F8E2CF;\n",
    "           font-size:120%;\n",
    "           font-family:Verdana;\n",
    "           text-align:center;\n",
    "           letter-spacing:0.5px\">\n",
    "<h1 style=\"padding: 25px;color:black;\">YOLOv5s</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wbvMlHd_QwMG",
    "outputId": "e8225db4-e61d-4640-8b1f-8bfce3331cea"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils' has no attribute 'notebook_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m display \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook_init\u001b[49m()  \u001b[38;5;66;03m# checks\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'utils' has no attribute 'notebook_init'"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5  # clone\n",
    "# %cd yolov5\n",
    "# %pip install -qr requirements.txt comet_ml  # install\n",
    "# !wandb disabled \n",
    "\n",
    "import torch\n",
    "# import utils\n",
    "# display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY2VXXXu74w5"
   },
   "source": [
    "# Train YOLOv5s on Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T20:23:44.086901Z",
     "iopub.status.busy": "2023-07-10T20:23:44.085883Z",
     "iopub.status.idle": "2023-07-10T20:42:30.736028Z",
     "shell.execute_reply": "2023-07-10T20:42:30.733045Z",
     "shell.execute_reply.started": "2023-07-10T20:23:44.086861Z"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "bbeeea2b-04fc-4185-aa64-258690495b5a"
   },
   "outputs": [],
   "source": [
    "# Train YOLOv5s on Guns & Knives Dataset for 10 epochs\n",
    "!python train.py --img 640 --batch 8 --epochs 10 --data /kaggle/input/guns-knives-object-detection/guns-knives-yolo/guns-knives-yolo/data.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-07-10T20:42:30.740361Z",
     "iopub.status.busy": "2023-07-10T20:42:30.739993Z",
     "iopub.status.idle": "2023-07-10T20:42:30.747217Z",
     "shell.execute_reply": "2023-07-10T20:42:30.74604Z",
     "shell.execute_reply.started": "2023-07-10T20:42:30.740328Z"
    }
   },
   "outputs": [],
   "source": [
    "# !zip -r /kaggle/working/last_run.zip /kaggle/working/yolov5/yolov5/runs/train/exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-07-10T20:42:30.749779Z",
     "iopub.status.busy": "2023-07-10T20:42:30.749455Z",
     "iopub.status.idle": "2023-07-10T20:42:30.764562Z",
     "shell.execute_reply": "2023-07-10T20:42:30.763608Z",
     "shell.execute_reply.started": "2023-07-10T20:42:30.749746Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python export.py --weights /kaggle/working/yolov5/yolov5/runs/train/exp3/weights/best.pt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# Detect\n",
    "```\n",
    "python detect.py --source 0  # webcam\n",
    "                          img.jpg  # image\n",
    "                          vid.mp4  # video\n",
    "                          screen  # screenshot\n",
    "                          path/  # directory\n",
    "                         'path/*.jpg'  # glob\n",
    "                         'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T20:47:04.943186Z",
     "iopub.status.busy": "2023-07-10T20:47:04.942768Z",
     "iopub.status.idle": "2023-07-10T20:47:16.95808Z",
     "shell.execute_reply": "2023-07-10T20:47:16.95688Z",
     "shell.execute_reply.started": "2023-07-10T20:47:04.943155Z"
    },
    "id": "zR9ZbuQCH7FX",
    "outputId": "284ef04b-1596-412f-88f6-948828dd2b49"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights /kaggle/working/yolov5/yolov5/runs/train/exp2/weights/best.pt --img 640 --conf 0.25 --source /kaggle/input/guns-knives-object-detection/guns-knives-yolo/guns-knives-yolo/test/images/ABsframe00214_jpg.rf.ae6c1e7d4c8e474123569e8bfa08f701.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Saving & Reusing Best Weights (best.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T20:47:51.407422Z",
     "iopub.status.busy": "2023-07-10T20:47:51.407038Z",
     "iopub.status.idle": "2023-07-10T20:47:51.412113Z",
     "shell.execute_reply": "2023-07-10T20:47:51.411036Z",
     "shell.execute_reply.started": "2023-07-10T20:47:51.40739Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T20:48:25.412029Z",
     "iopub.status.busy": "2023-07-10T20:48:25.411624Z",
     "iopub.status.idle": "2023-07-10T20:48:25.87452Z",
     "shell.execute_reply": "2023-07-10T20:48:25.87349Z",
     "shell.execute_reply.started": "2023-07-10T20:48:25.411993Z"
    },
    "id": "GMusP4OAxFu6"
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('','custom', path='/kaggle/working/yolov5/yolov5/runs/train/exp2/weights/best.pt',force_reload=True,source='local')\n",
    "im1 = model(\"/kaggle/input/guns-knives-object-detection/guns-knives-yolo/guns-knives-yolo/test/images/ABsframe00214_jpg.rf.ae6c1e7d4c8e474123569e8bfa08f701.jpg\")\n",
    "im2 = model(\"/kaggle/input/guns-knives-object-detection/guns-knives-yolo/guns-knives-yolo/test/images/DefenseKnifeAttack0898_jpg.rf.7bb618a37cc2fe0a9178105fda35c3bf.jpg\")\n",
    "im1.show() # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "im2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T20:48:35.51195Z",
     "iopub.status.busy": "2023-07-10T20:48:35.511566Z",
     "iopub.status.idle": "2023-07-10T20:48:35.717168Z",
     "shell.execute_reply": "2023-07-10T20:48:35.713335Z",
     "shell.execute_reply.started": "2023-07-10T20:48:35.51192Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "img = mpimg.imread(\"/kaggle/working/yolov5/runs/detect/exp3/DefenseKnifeAttack0093_jpg.rf.8d998dae5f0fabb1cd0264e83818327d.jpg\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off') \n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "img = mpimg.imread(\"/kaggle/working/yolov5/runs/detect/exp5/ABsframe00214_jpg.rf.ae6c1e7d4c8e474123569e8bfa08f701.jpg\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#F8E2CF;\n",
    "           font-size:120%;\n",
    "           font-family:Verdana;\n",
    "           text-align:center;\n",
    "           letter-spacing:0.5px\">\n",
    "<h1 style=\"padding: 25px;color:black;\">FasterRCNN MobileNet v3</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-07-14T13:48:43.996159Z",
     "iopub.status.busy": "2023-07-14T13:48:43.995634Z",
     "iopub.status.idle": "2023-07-14T13:49:42.022981Z",
     "shell.execute_reply": "2023-07-14T13:49:42.021597Z",
     "shell.execute_reply.started": "2023-07-14T13:48:43.996123Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install pycocotools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import functional as FT\n",
    "from torchvision import transforms as T\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, sampler, random_split, Dataset\n",
    "import copy\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A  # our data augmentation library\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict, deque\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm # progress bar\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from pycocotools.coco import COCO\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:42.026566Z",
     "iopub.status.busy": "2023-07-14T13:49:42.026235Z",
     "iopub.status.idle": "2023-07-14T13:49:42.047084Z",
     "shell.execute_reply": "2023-07-14T13:49:42.045878Z",
     "shell.execute_reply.started": "2023-07-14T13:49:42.026529Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_transforms(train=False):\n",
    "    if train:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(600, 600),\n",
    "            A.HorizontalFlip(p=0.3),\n",
    "            A.VerticalFlip(p=0.3),\n",
    "            A.RandomBrightnessContrast(p=0.1),\n",
    "            A.ColorJitter(p=0.1),\n",
    "            ToTensorV2()\n",
    "        ], bbox_params=A.BboxParams(format='coco'))\n",
    "    else:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(600, 600), \n",
    "            ToTensorV2()\n",
    "        ], bbox_params=A.BboxParams(format='coco'))\n",
    "    return transform\n",
    "\n",
    "class DatasetDetection(datasets.VisionDataset):\n",
    "    def __init__(self, root, split='train', transform=None, target_transform=None, transforms=None):\n",
    "        super().__init__(root, transforms, transform, target_transform)\n",
    "        self.split = split #train, valid, test\n",
    "        self.coco = COCO(os.path.join(root, split, \"_annotations.coco.json\")) # annotatiosn stored here\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.ids = [id for id in self.ids if (len(self._load_target(id)) > 0)]\n",
    "    \n",
    "    def _load_image(self, id: int):\n",
    "        path = self.coco.loadImgs(id)[0]['file_name']\n",
    "        image = cv2.imread(os.path.join(self.root, self.split, path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "    def _load_target(self, id):\n",
    "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id = self.ids[index]\n",
    "        image = self._load_image(id)\n",
    "        target = self._load_target(id)\n",
    "        target = copy.deepcopy(self._load_target(id))\n",
    "        \n",
    "        boxes = [t['bbox'] + [t['category_id']] for t in target] \n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, bboxes=boxes)\n",
    "        \n",
    "        image = transformed['image']\n",
    "        boxes = transformed['bboxes']\n",
    "        \n",
    "        new_boxes = [] # convert from xywh to xyxy\n",
    "        for box in boxes:\n",
    "            xmin = box[0]\n",
    "            xmax = xmin + box[2]\n",
    "            ymin = box[1]\n",
    "            ymax = ymin + box[3]\n",
    "            new_boxes.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        boxes = torch.tensor(new_boxes, dtype=torch.float32)\n",
    "        \n",
    "        targ = {}\n",
    "        targ['boxes'] = boxes\n",
    "        targ['labels'] = torch.tensor([t['category_id'] for t in target], dtype=torch.int64)\n",
    "        targ['image_id'] = torch.tensor([t['image_id'] for t in target])\n",
    "        targ['area'] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) # we have a different area\n",
    "        targ['iscrowd'] = torch.tensor([t['iscrowd'] for t in target], dtype=torch.int64)\n",
    "        return image.div(255), targ \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:42.050452Z",
     "iopub.status.busy": "2023-07-14T13:49:42.050101Z",
     "iopub.status.idle": "2023-07-14T13:49:42.374815Z",
     "shell.execute_reply": "2023-07-14T13:49:42.37388Z",
     "shell.execute_reply.started": "2023-07-14T13:49:42.050418Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/kaggle/input/guns-knives-object-detection/guns-knives-coco/guns-knives-coco\"\n",
    "coco = COCO(os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"))\n",
    "categories = coco.cats\n",
    "n_classes = len(categories.keys())\n",
    "classes = [i[1]['name'] for i in categories.items()]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:42.378099Z",
     "iopub.status.busy": "2023-07-14T13:49:42.377318Z",
     "iopub.status.idle": "2023-07-14T13:49:42.444427Z",
     "shell.execute_reply": "2023-07-14T13:49:42.443376Z",
     "shell.execute_reply.started": "2023-07-14T13:49:42.378073Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = DatasetDetection(root=dataset_path, split='train', transforms=get_transforms(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:42.446265Z",
     "iopub.status.busy": "2023-07-14T13:49:42.445901Z",
     "iopub.status.idle": "2023-07-14T13:49:42.925909Z",
     "shell.execute_reply": "2023-07-14T13:49:42.925014Z",
     "shell.execute_reply.started": "2023-07-14T13:49:42.446231Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = train_dataset[23]\n",
    "img_int = torch.tensor(sample[0] * 255, dtype=torch.uint8)\n",
    "plt.imshow(draw_bounding_boxes(\n",
    "    img_int, sample[1]['boxes'], [classes[i] for i in sample[1]['labels']], width=4\n",
    ").permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:42.927283Z",
     "iopub.status.busy": "2023-07-14T13:49:42.926931Z",
     "iopub.status.idle": "2023-07-14T13:49:44.227643Z",
     "shell.execute_reply": "2023-07-14T13:49:44.226458Z",
     "shell.execute_reply.started": "2023-07-14T13:49:42.927251Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features # we need to change the head\n",
    "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:44.230487Z",
     "iopub.status.busy": "2023-07-14T13:49:44.229829Z",
     "iopub.status.idle": "2023-07-14T13:49:44.235642Z",
     "shell.execute_reply": "2023-07-14T13:49:44.234665Z",
     "shell.execute_reply.started": "2023-07-14T13:49:44.230345Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:44.237556Z",
     "iopub.status.busy": "2023-07-14T13:49:44.23699Z",
     "iopub.status.idle": "2023-07-14T13:49:51.295239Z",
     "shell.execute_reply": "2023-07-14T13:49:51.294044Z",
     "shell.execute_reply.started": "2023-07-14T13:49:44.237525Z"
    }
   },
   "outputs": [],
   "source": [
    "images,targets = next(iter(train_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k:v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:49:51.29747Z",
     "iopub.status.busy": "2023-07-14T13:49:51.297083Z",
     "iopub.status.idle": "2023-07-14T13:49:51.310276Z",
     "shell.execute_reply": "2023-07-14T13:49:51.309371Z",
     "shell.execute_reply.started": "2023-07-14T13:49:51.297438Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, loader, device, epoch, history):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    all_losses = []\n",
    "    all_losses_dict = []\n",
    "    \n",
    "    for images, targets in tqdm(loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets) \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_dict_append = {k: v.item() for k, v in loss_dict.items()}\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        all_losses.append(loss_value)\n",
    "        all_losses_dict.append(loss_dict_append)\n",
    "        \n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping trainig\")\n",
    "            print(loss_dict)\n",
    "            sys.exit(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    history.append(all_losses_dict)\n",
    "    all_losses_dict = pd.DataFrame(all_losses_dict)\n",
    "    print(\"Epoch {}, lr: {:.6f}, loss: {:.6f}, loss_classifier: {:.6f}, loss_box: {:.6f}, loss_rpn_box: {:.6f}, loss_object: {:.6f}\".format(\n",
    "        epoch, optimizer.param_groups[0]['lr'], np.mean(all_losses),\n",
    "        all_losses_dict['loss_classifier'].mean(),\n",
    "        all_losses_dict['loss_box_reg'].mean(),\n",
    "        all_losses_dict['loss_rpn_box_reg'].mean(),\n",
    "        all_losses_dict['loss_objectness'].mean()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:50:20.458759Z",
     "iopub.status.busy": "2023-07-14T13:50:20.458368Z",
     "iopub.status.idle": "2023-07-14T13:52:41.037222Z",
     "shell.execute_reply": "2023-07-14T13:52:41.036104Z",
     "shell.execute_reply.started": "2023-07-14T13:50:20.458729Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs=1\n",
    "history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:53:49.860636Z",
     "iopub.status.busy": "2023-07-14T13:53:49.86024Z",
     "iopub.status.idle": "2023-07-14T13:53:50.050428Z",
     "shell.execute_reply": "2023-07-14T13:53:50.049417Z",
     "shell.execute_reply.started": "2023-07-14T13:53:49.860603Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"/kaggle/working/frcnn-mobilenetv3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:54:45.386043Z",
     "iopub.status.busy": "2023-07-14T13:54:45.384788Z",
     "iopub.status.idle": "2023-07-14T13:54:45.54482Z",
     "shell.execute_reply": "2023-07-14T13:54:45.543846Z",
     "shell.execute_reply.started": "2023-07-14T13:54:45.386001Z"
    }
   },
   "outputs": [],
   "source": [
    "loadedModel = torch.load(\"/kaggle/working/frcnn-mobilenetv3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:54:50.863594Z",
     "iopub.status.busy": "2023-07-14T13:54:50.863208Z",
     "iopub.status.idle": "2023-07-14T13:54:50.901223Z",
     "shell.execute_reply": "2023-07-14T13:54:50.899881Z",
     "shell.execute_reply.started": "2023-07-14T13:54:50.863563Z"
    }
   },
   "outputs": [],
   "source": [
    "loadedModel.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:54:54.456597Z",
     "iopub.status.busy": "2023-07-14T13:54:54.456223Z",
     "iopub.status.idle": "2023-07-14T13:54:54.477986Z",
     "shell.execute_reply": "2023-07-14T13:54:54.477073Z",
     "shell.execute_reply.started": "2023-07-14T13:54:54.456565Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = DatasetDetection(root=dataset_path, split=\"test\", transforms=get_transforms(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:55:01.941074Z",
     "iopub.status.busy": "2023-07-14T13:55:01.940717Z",
     "iopub.status.idle": "2023-07-14T13:55:02.306158Z",
     "shell.execute_reply": "2023-07-14T13:55:02.305314Z",
     "shell.execute_reply.started": "2023-07-14T13:55:01.941044Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = test_dataset[20]\n",
    "img_int = torch.tensor(sample[0] * 255, dtype=torch.uint8)\n",
    "plt.imshow(draw_bounding_boxes(\n",
    "    img_int, sample[1]['boxes'], [classes[i] for i in sample[1]['labels']], width=4\n",
    ").permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T13:55:08.005333Z",
     "iopub.status.busy": "2023-07-14T13:55:08.004969Z",
     "iopub.status.idle": "2023-07-14T13:55:08.572694Z",
     "shell.execute_reply": "2023-07-14T13:55:08.571796Z",
     "shell.execute_reply.started": "2023-07-14T13:55:08.005303Z"
    }
   },
   "outputs": [],
   "source": [
    "img, _ = test_dataset[20]\n",
    "img_int = torch.tensor(img*255, dtype=torch.uint8)\n",
    "with torch.no_grad():\n",
    "    prediction = loadedModel([img.to(device)])\n",
    "    pred = prediction[0]\n",
    "    \n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "plt.imshow(draw_bounding_boxes(img_int,pred['boxes'][pred['scores'] > 0.5],\n",
    "    [classes[i] for i in pred['labels'][pred['scores'] > 0.5].tolist()], width=4,colors=(255,0,0)\n",
    ").permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#F8E2CF;\n",
    "           font-size:120%;\n",
    "           font-family:Verdana;\n",
    "           text-align:center;\n",
    "           letter-spacing:0.5px\">\n",
    "<h1 style=\"padding: 25px;color:black;\">FasterRCNN ResNet50</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T11:26:14.584516Z",
     "iopub.status.busy": "2023-07-13T11:26:14.584138Z",
     "iopub.status.idle": "2023-07-13T11:26:15.994262Z",
     "shell.execute_reply": "2023-07-13T11:26:15.993296Z",
     "shell.execute_reply.started": "2023-07-13T11:26:14.584488Z"
    }
   },
   "outputs": [],
   "source": [
    "# lets load the faster rcnn model\n",
    "# model = models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features # we need to change the head\n",
    "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T11:28:05.626887Z",
     "iopub.status.busy": "2023-07-13T11:28:05.626464Z",
     "iopub.status.idle": "2023-07-13T11:28:25.855104Z",
     "shell.execute_reply": "2023-07-13T11:28:25.853925Z",
     "shell.execute_reply.started": "2023-07-13T11:28:05.626856Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "\n",
    "images,targets = next(iter(train_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k:v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)\n",
    "device = torch.device(\"cuda\") \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T11:28:25.857588Z",
     "iopub.status.busy": "2023-07-13T11:28:25.857247Z",
     "iopub.status.idle": "2023-07-13T11:28:25.864674Z",
     "shell.execute_reply": "2023-07-13T11:28:25.863808Z",
     "shell.execute_reply.started": "2023-07-13T11:28:25.857559Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        history['loss_classifier']= \n",
    "        history['loss_box_reg'] = \n",
    "        history['loss_objectness'] = \n",
    "        history['loss_rpn_box_reg']  ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T11:59:59.339821Z",
     "iopub.status.busy": "2023-07-13T11:59:59.339329Z",
     "iopub.status.idle": "2023-07-13T11:59:59.353025Z",
     "shell.execute_reply": "2023-07-13T11:59:59.351736Z",
     "shell.execute_reply.started": "2023-07-13T11:59:59.339775Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_arr = []\n",
    "loss_classifier = []\n",
    "loss_box_reg = []\n",
    "loss_objectness = []\n",
    "loss_rpn_box_reg = []\n",
    "\n",
    "def train_one_epoch(model, optimizer, loader, device, epoch):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    all_losses = []\n",
    "    all_losses_dict = []\n",
    "    \n",
    "    for images, targets in tqdm(loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets) # the model computes the loss automatically if we pass in targets\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_dict_append = {k: v.item() for k, v in loss_dict.items()}\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        all_losses.append(loss_value)\n",
    "        all_losses_dict.append(loss_dict_append)\n",
    "        epoch_arr.append(epoch)\n",
    "        loss_classifier.append(loss_dict_append['loss_classifier'])\n",
    "        loss_box_reg.append(loss_dict_append['loss_box_reg'])\n",
    "        loss_objectness.append(loss_dict_append['loss_objectness'])\n",
    "        loss_rpn_box_reg.append(loss_dict_append['loss_rpn_box_reg'])\n",
    "        \n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping trainig\") # train if loss becomes infinity\n",
    "            print(loss_dict)\n",
    "            sys.exit(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#     history_resnet50[epoch] = all_losses_dict\n",
    "    all_losses_dict = pd.DataFrame(all_losses_dict) # for printing\n",
    "    print(\"Epoch {}, lr: {:.6f}, loss: {:.6f}, loss_classifier: {:.6f}, loss_box: {:.6f}, loss_rpn_box: {:.6f}, loss_object: {:.6f}\".format(\n",
    "        epoch, optimizer.param_groups[0]['lr'], np.mean(all_losses),\n",
    "        all_losses_dict['loss_classifier'].mean(),\n",
    "        all_losses_dict['loss_box_reg'].mean(),\n",
    "        all_losses_dict['loss_rpn_box_reg'].mean(),\n",
    "        all_losses_dict['loss_objectness'].mean()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T12:20:33.239875Z",
     "iopub.status.busy": "2023-07-13T12:20:33.239193Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs=5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_resnet50 = pd.DataFrame()\n",
    "history_resnet50[\"epoch\"] = epoch_arr\n",
    "history_resnet50[\"loss_classifier\"] = loss_classifier\n",
    "history_resnet50[\"loss_box_reg\"] = loss_box_reg\n",
    "history_resnet50[\"loss_objectness\"] = loss_objectness\n",
    "history_resnet50[\"loss_rpn_box_reg\"] = loss_rpn_box_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1,figsize=(10, 20))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "sns.lineplot(data=history_resnet50,x=history_resnet50.index,y=\"loss_classifier\",palette=\"flare\",errorbar = None,hue=\"epoch\");\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "sns.lineplot(history_resnet50[\"loss_box_reg\"],palette=\"flare\",errorbar = None);\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "sns.lineplot(history_resnet50[\"loss_objectness\"],palette=\"flare\",errorbar = None);\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "sns.lineplot(history_resnet50[\"loss_rpn_box_reg\"],palette=\"flare\",errorbar = None);\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DatasetDetection(root=dataset_path, split=\"test\", transforms=get_transforms(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(20, 20))\n",
    "\n",
    "img, _ = test_dataset[20]\n",
    "img_int = torch.tensor(img*255, dtype=torch.uint8)\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])\n",
    "    pred = prediction[0]\n",
    "    \n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(draw_bounding_boxes(img_int,pred['boxes'][pred['scores'] > 0.5],\n",
    "    [classes[i] for i in pred['labels'][pred['scores'] > 0.5].tolist()], width=4,colors=(255,0,0)\n",
    ").permute(1, 2, 0))\n",
    "\n",
    "img, _ = test_dataset[30]\n",
    "img_int = torch.tensor(img*255, dtype=torch.uint8)\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])\n",
    "    pred = prediction[0]\n",
    "    \n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(draw_bounding_boxes(img_int,pred['boxes'][pred['scores'] > 0.5],\n",
    "    [classes[i] for i in pred['labels'][pred['scores'] > 0.5].tolist()], width=4,colors=(255,0,0)\n",
    ").permute(1, 2, 0))\n",
    "\n",
    "img, _ = test_dataset[40]\n",
    "img_int = torch.tensor(img*255, dtype=torch.uint8)\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])\n",
    "    pred = prediction[0]\n",
    "    \n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(draw_bounding_boxes(img_int,pred['boxes'][pred['scores'] > 0.5],\n",
    "    [classes[i] for i in pred['labels'][pred['scores'] > 0.5].tolist()], width=4,colors=(255,0,0)\n",
    ").permute(1, 2, 0))\n",
    "\n",
    "img, _ = test_dataset[50]\n",
    "img_int = torch.tensor(img*255, dtype=torch.uint8)\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])\n",
    "    pred = prediction[0]\n",
    "    \n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(draw_bounding_boxes(img_int,pred['boxes'][pred['scores'] > 0.5],\n",
    "    [classes[i] for i in pred['labels'][pred['scores'] > 0.5].tolist()], width=4,colors=(255,0,0)\n",
    ").permute(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
